
#THIS IS FOR TESTING OF IMAGE

from ultralytics import YOLO
import matplotlib.pyplot as plt

# Load the image and the trained model
image_path = r"C:\Users\anish\Downloads\üêãüí¶ Dive deep into the art of underwater‚Ä¶.jpeg" #image file path 
model_path = r"C:\Users\anish\Downloads\yolo_trained_model\content\runs\detect\train\weights\best.pt" #this is my model file path 

model = YOLO(model_path)

# prediction on the image
results = model.predict(source=image_path, conf=0.3)
result = results[0]

# Show detections
for box in result.boxes:
    class_id = int(box.cls)
    conf = float(box.conf)
    class_name = model.names[class_id]
    print(f"{class_name} ({conf:.2f})")

# Display the image with bounding boxes
plt.imshow(result.plot())
plt.axis('off')
plt.show()

#THIS IS FOR TESTING OF VIDEO 

from ultralytics import YOLO  # Import YOLO class from the ultralytics package

# Path to the video file 
video = r"C:\Users\anish\Downloads\videoplayback.webm"  

# Loading my trained YOLO model from the local path
model = YOLO(r"C:\Users\anish\Downloads\yolo_trained_model\content\runs\detect\train\weights\best.pt")

import cv2  # Import OpenCV for video processing and display


cap = cv2.VideoCapture(video)

ret = True  # Initialize a flag to enter the while loop

while ret:
    ret, frame = cap.read() 
    if ret:
        results = model.predict(source=frame, save=False, imgsz=640)  # imgsz resizes input to 640x640

        # Draw bounding boxes and class labels on the frame
        annotated_frame = results[0].plot()

        # Display the annotated frame in a window
        cv2.imshow("YOLOv8 Detection", annotated_frame)

        # Wait for 1 millisecond and check if 'q' key is pressed to quit
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

# Release the video capture object
cap.release()

# Close all OpenCV windows
cv2.destroyAllWindows()
